---
layout: post
title: 考核题库-2
abbrlink: 18464cd734e94bfbb39fab913bb55e96
tags: []
categories:
  - 工作笔记
  - 会议摘要
date: 1756370456334
updated: 1756370499412
---

**单选题（7道）**

**1. 在 AI 生产力平台中创建新应用时，第一个关键决策是选择应用类型。如果想要创建一个能进行多轮对话的客服助手，最应该选择哪种类型？**\
A. 视觉生成 应用\
B. 我的助手应用\
C. 视觉生成应用\
D. 业务流应用\
**答案：B**\
**解析：** 对话（Chat）应用类型是专门为多轮、有上下文关联的交互场景设计的，它内置了管理对话历史的功能。

**2. 配置应用的核心是提示词工程。在对话应用的“角色与提示词”部分，哪一部分主要用于定义AI的个性、专业领域和回答风格？**\
A. 上下文\
B. 变量\
C. 开场白\
D. 系统提示词（System Prompt）\
**答案：D**\
**解析：** 系统提示词（System Prompt）是指导AI行为最根本的指令，通常用于设定AI的角色（如“你是一位专业的法律顾问”）、回答原则和边界，它对模型的输出风格起着奠基性作用。

**3. 小王想让用户在与AI对话时，能手动切换回答的“创意程度”（如从“严谨”到“脑洞大开”）。他应该在应用配置中利用哪个功能来实现？**\
A. 在知识库中上传不同风格的文档。\
B. 在提示词中使用“变量”，并创建一个名为“creativity”的变量，将其与模型参数“温度”关联。\
C. 为同一个应用集成多个不同的大语言模型。\
D. 在“模型与参数”中，将“温度”参数固定为一个较高的值。\
**答案：B**\
**解析：** Dify的“变量”功能允许将前端用户输入与后端��型参数动态绑定。创建一个滑块变量并关联到“温度”（Temperature）参数，用户就可以实时调整这个参数，从而控制生成文本的随机性和创造性。

**4. 在“模型与参数”配置中，“最大令牌数（Max Tokens）”的主要作用是？**\
A. 控制AI生成单次回复的最大长度，防止回复过长或消耗过多Token。\
B. 设置用户问题的最大长度限制。\
C. 调整模型思考问题的计算时间。\
D. 限制知识库检索时返回的文本片段数量。\
**答案：A**\
**解析：** “最大令牌数”直接限制模型输出内容的最大长度，以Token数为单位。设置此参数可以有效控制单次交互的成本和响应内容的篇幅。

**5. 一个应用配置完成后，在正式发布给用户使用前，最重要的一步是什么？**\
A. 配置最好的模型。\
B. 使用界面右上角的“发布”按钮，将应用从“草稿”状态发布为“上线”状态。\
C. 在社交媒体上提前预告。\
D. 反复使用“调试”窗口进行测试，并根据结果优化提示词、参数或知识库。\
**答案：D**\
**解析：** 调试是迭代和优化应用的核心环节。通过模拟真实用户提问，可以不断发现提示词歧义、参数不合理或知识库检索失败等问题，确保应用上线后能达到预期效果。

**6. 如果想要将配置好的AI应用嵌入到公司现有的网站中，应该使用提供的哪种方式？**\
A. 将应用导出为可执行文件（.exe）。\
B. 在“发布”设置中，获取并部署API接口或嵌入iframe代码段。\
C. 将应用配置截图发给网站开发人员。\
D. 邀请网站用户全部注册平台账号。\
**答案：B**\
**解析：** 通过API可供后端深度集成，通过生成的iframe代码可直接嵌入到网页的某个区域，这是最标准且高效的嵌入方式。

**7. 在配置一个需要查询知识库的应用时，“召回测试”中“TOP K”选项的特点是？**\
A. 返回的结果数量较少，但与问题相关性极高。\
B. 返回的结果数量较多，尽可能覆盖所有可能相关的文本片段。\
C. 检索速度最快，但精度最低。\
D. 仅检索最近上传的文档。\
**答案：B**\
**解析：** “高召回”模式以提高召回率为目标，倾向于返回更多数量的相关文本片段，即使部分片段相关性可能稍低，旨在避免遗漏任何潜在有用的信息。

***

**多选题（3道）**

**1. 【多选题】以下哪些是可以在“提示词”中通过“变量”来实现的功能？**\
A. 让用户在聊天前自由填写一个“角色”下拉框（如：老师、学生、专家），使AI根据不同角色调整回答口吻。\
B. 创建一个文本框，让用户输入他们公司的名称，使AI在生成的文案中动态插入该名称。\
C. 创建一个滑块，让用户实时调整模型应答的“温度”（Temperature）参数。\
D. 直接修改大语言模型的内部权重。\
E. 设置一个开关，让用户决定本次对话是否启用知识库检索。\
**答案：A, B, C**\
**解析：** 变量是连接用户输入和提示词/模型参数的桥梁。A、B、C都是变量的典型应用场景。D是绝对不可能的。E是一个高级功能，通常需要通过“工作流”来实现逻辑判断，而非简单的变量。

**2. 【多选题】在“调试”一个对话应用时，发现AI的回答没有按预期从知识库中获取信息，而是基于模型自身知识泛泛而谈。导致这个问题可能的原因是？**\
A. 知识库中的文档尚未完成索引处理。\
B. 系统提示词中忘记加入“请根据<知识库>内容回答”等类似指令。\
C. 在“模型与参数”中，“温度”值设置得太低。\
D. 在“上下文”配置中，没有开启“检索知识库”功能或未正确关联知识库。\
**答案：A, B, D**\
**解析：** A导致无内容可检索；B导致AI即使拿到了检索结果也不知道要用它；D是根本性的功能开关未打开。C（温度低）只会让回答更确定性，但不会影响是否检索知识库这一行为。

**3. 【多选题】关于应用的“发布与协作”，以下说法正确的是？**\
A. 可以将应用权限设置为“私有”，仅限自己或团队内成员访问。\
B. 可以将应用权限设置为“公开”，任何人通过链接都可访问，无需API密钥。\
C. 可以在应用设置白名单，限制 URL 的访问登录。\
D. 一旦应用发布上线，其所有配置（包括提示词）都无法再被修改。\
**答案：A, B, C**\
**解析：** A、B、C都是Dify核心的协作和发布功能。D是错误的，应用上线后可以随时修改配置（会保存为新版本），并需要重新发布才能使最新修改生效，这实现了应用的迭代更新。

**加分题：**

**1. 【多选题】您正在为客户设计一个高性能、低延迟且需要控制成本的AI应用。该应用部署在Dify上，预计会有大量用户并发访问。以下哪些配置策略是合理且有效的？**\
A. **模型选型**：在所有环境下（调试、预览、生产）都统一使用性能最强的GPT-4模型，以确保体验一致。\
B. **缓存策略**：开启“对话内存”或类似缓存功能，对频繁出现的相似问题及答案进行缓存，减少对LLM API的重复调用。\
C. **异步处理**：对于处理时间可能较长的复杂“工作流”任务（如生成报告），配置异步处理并提供任务ID，让用户稍后查询结果，避免请求超时。\
D. **性能与成本平衡**：在生产环境中，对知识库检索和对话生成使用高性能模型（如GPT-4），但对简单的意图分类或文本总结任务使用更具性价比的模型（如GPT-3.5-Turbo）。\
E. **监控与告警**：在Dify后台密切关注应用的Token消耗、响应延迟和API错误率，并设置预算告警，以便在成本异常激增时及时干预。\
F. **硬件扩容**：为了应对高并发，建议客户为Dify的服务器采购更多的CPU核心，因为LLM的计算负载主要消耗CPU资源。

**答案：B, C, E**

**解析：**

· **A（错误）**：这是一个成本控制上的反面教材。在调试和内部测试阶段使用昂贵的GPT-4会造成巨大的浪费。合理的策略是：调试阶段用廉价模型（如GPT-3.5-Turbo）迭代提示词，最终生产环境再根据效果需求评估是否升级到更强模型。

· **B（正确）**：缓存是应对高并发、降低延迟和成本的经典手段。将常见QA对缓存起来，可以直接快速响应，无需调用模型，极大提升效率。

· **C（正确）**：这是处理长耗时任务的最佳实践。同步等待会导致连接超时和用户体验极差。将其异步化，立即返回一个“任务已接收”的响应，后续通过轮询或Webhook通知用户获取结果，是更专业的架构设计。

· **D（错误 - 部分正确）**：这个思路（在应用内不同环节使用不同模型）本身非常先进，被称为“模型路由”或“ cascading ”，是平衡成本与效果的高级策略。**然而**，在标准版的Dify中，一个应用通常只能关联一个主模型进行文本生成，暂时还无法在单个应用内如此精细地为不同功能分配不同模型（此功能可能需要通过自定义代码/workflow实现）。因此，作为标准功能的考察，此项不选。

· **E（正确）**：监控是运维和成本控制的基石。密切监控核心指标并设置告警，可以帮助团队快速发现性能瓶颈、API故障或成本异常（如提示词错误导致循环调用），是保障应用稳定、可控运行的必备措施。

· **F（错误）**：这是一个常见的误解。对于使用Dify SaaS服务或基于API调用云厂商（如OpenAI, Anthropic）模型的用户来说，**LLM的推理计算完全发生在模型提供商的服务器上**，消耗的是他们的GPU资源。Dify自身的服务器主要负责业务流程编排、知识库检索等任务。因此，应用的并发能力和响应速度主要受限于模型提供商的API速率限制和网络延迟，与客户本地或托管Dify的服务器的CPU关系不大。本地部署大模型的情况除外。

 

２、知识库的高级解析模式功能，新增加文件图像处理

A、可以不用写图像分析提示词

B 、视觉模型对图片进行处理，是在Embedding 前

C、视觉模型能对图片进行理解、分析和总结，并总结和文本内容一起Embedding

D、视觉模型处理的图片内容只在文件分段用figures作为标识展示

**答案：A、B、C** 、D

 
