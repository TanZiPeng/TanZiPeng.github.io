---
layout: post
title: 考核题库-1
abbrlink: cf61ca5364be4baf95102afb197510bd
tags: []
categories:
  - 工作笔记
  - 会议摘要
date: 1756370268489
updated: 1756370491578
---

**单选题（7道）**

**1. 客户上传了一份包含详细产品信息的PDF文档到知识库，希望AI能基于此回答问题。但AI的回答时常不准确或“幻觉”。以下哪项措施是提升回答准确性的【最有效】首选方法？**\
A. 在应用设置中大幅提高“温度（Temperature）”参数值。\
B. 检查并优化知识库文档的分段（Chunk）策略，确保关键信息被正确提取。\
C. 在提示词模板中删除所有关于“请根据知识库回答”的指令。\
D. 为应用切换一个更昂贵的大语言模型（LLM）。\
**答案：B**\
**解析：** 分段是知识库处理的核心，不合理的分段（如截断了关键信息）会直接导致检索失败，从而引发模型幻觉。调整分段是解决此类问题的根本手段。

**2. 在配置知识库的“分段处理”规则时，“重叠区（Overlap）”的主要作用是？**\
A. 减少知识库存储空间占用，提升处理速度。\
B. 防止在分段时，一个完整的语义或关键信息被割裂到两个段落中，保证检索上下文连贯。\
C. 用于标记文档中重复的内容，以便AI在回答时进行去重。\
D. 设置多个知识库之间的关联优先级。\
**答案：B**\
**解析：** 重叠区通过在相邻分段之间保留一部分重复文本，来确保当一个概念或句子被分段切断时，其在相邻段中仍有完整呈现，从而大幅提升检索的准确性。

**3. 小李为知识库上传了一个包含最新公司政策的Word文档。上传成功后，他直接去测试应用，发现AI给出的还是旧政策的内容。最可能的原因是什么？**\
A. 上传的Word文档格式不被平台支持。\
B. 知识库处理需要时间，文档尚未完成索引（Indexing）。\
C. 应用的对话提示词（Prompt）编写有误。\
D. 当前使用的LLM模型没有该领域知识。\
**答案：B**\
**解析：** 文档上传后，Dify需要在后台进行解析、分段和向量化（索引）处理，这个过程需要一定时间。在索引完成前，新知识不会被检索到。

**4. 知识库目前标准模式【不支持】处理以下哪种类型的文件？**\
A. Markdown (.md)\
B. PowerPoint演示文稿 (.pptx)\
C. 图片文件 (.jpg, .png)\
D. 文本文件（.txt)\
**答案：D**\
**解析：** Dify的知识库主要处理文本类信息。对于.jpg、.png等图片文件，它无法直接提取其中的文字内容（除非使用专家模式的视觉模型，但标准知识库不包含此功能）。其他选项格式均为支持类型。

**5. 如果想要确保AI应用在回答用户问题时，严格遵循知识库内容而绝不进行自由发挥，首先应该优化哪个部分？**\
A. 在模型提供商处申请更多的API额度。\
B. 在应用的“提示词”中明确加入强约束指令，如“严格根据提供的知识库内容回答，如果知识库中没有相关信息，请明确告知用户不知道”。\
C. 删除知识库中所有不重要的文档。\
D. 将检索模式从“高精度”切换到“高召回”。\
**答案：B**\
**解析：** 提示词是指导AI行为的最直接工具。通过强约束指令，可以有效地约束模型的生成范围，这是防止幻觉和自由发挥的首要且最有效的方法。

**6. 知识库中的“相似度阈值”设置主要影响什么？**\
A. 控制每次调用知识库检索所消耗的Token数量。\
B. 决定检索出的文本片段与用户问题相关性的最低分数，用于过滤掉低相关度的结果。\
C. 调整知识库处理文档时的并行任务数量。\
D. 设置用户提问和AI回答之间的响应时间延迟。\
**答案：B**\
**解析：** 相似度阈值是一个分数门槛。高于此门槛的文本片段会被视为相关并返回给模型作为上下文，低于此门槛的则被过滤掉。调高阈值会让检索更严格（相关度更高但结果可能更少），调低阈值则更宽松（结果更多但可能包含不相关信息）。

**7. 知识库的“检索模式”中，“高精度”和“高召回”的主要区别在于？**\
A. 高精度模式响应速度更快，高召回模式响应速度更慢。\
B. 高精度模式更倾向于返回少量高度相关的结果，高召回模式更倾向于返回大量可能相关的结果。\
C. 高精度模式消耗的算力更少，高召回模式消耗的算力更多。\
D. 高精度模式仅支持英文检索，高召回模式支持多语言检索。\
**答案：B**\
**解析：** 这是信息检索领域的经典概念。高精度（Precision）追求“返回的都是对的”，高召回（Recall）追求“对的都被返回了”。在Dify中，这通常通过调整底层检索算法（如MMR）的参数来实现。

 

**多选题（3道）**

**1. 【多选题】以下哪些因素会直接影响知识库的检索效果和最终回答质量？**\
A. 源文档的质量和清晰度。\
B. 知识库的分段（Chunk）长度和重叠区（Overlap）设置。\
C. 所选用的嵌入模型（Embedding Model）的性能。\
D. 应用提示词（Prompt）中对知识库使用方式的指令。\
E. 网站前端的UI配色方案。\
**答案：A, B, C, D**\
**解析：** A是数据源头，垃圾进垃圾出；B是数据处理的核心参数；C决定了文本转换为向量后语义保真度，影响检索准确性；D直接指挥AI如何利用检索到的上下文。E属于前端展示，与后端检索逻辑无关。

**2. 【多选题】一位客户希望为其大型法律文档库（包含数万份PDF合同和条款文件）构建一个精准的AI问答应用。在使用Dify知识库功能时，为保障项目成功，您作为售前工程师会建议他重点关注并做好以下哪些方面的规划？**\
A. **成本规划**：预估大量文档嵌入（Embedding）处理以及后续高频问答所产生的Token消耗成本，尤其是选用按量付费的模型时。\
B. **分段策略调优**：法律文档逻辑严密，需精心调试分段长度和重叠区，确保关键条款（如免责声明、责任限制）的完整性不被破坏。\
C. **模型选型**：必须选择最昂贵、参数最多的LLM（如GPT-4），因为只有它才能理解复杂的法律语言。\
D. **索引性能与时效性**：提前评估数万份文档的首次索引所需时间，并为其设计一套文档更新后的手动或自动重新索引流程。\
E. **提示词工程**：在提示词中必须严格限定AI的回答范围和语气（如“仅作为参考，不构成法律建议”），并设计对“未找到答案”情况的稳妥回复策略。\
F. **硬件配置**：建议客户为Dify服务部署独立的GPU服务器，因为知识库检索速度完全依赖于本地GPU算力。

**答案：A, B, D, E**

**解析：**

· **A（正确）**：这是一个非常实际的考量。处理海量文档会产生高昂的嵌入成本，后续每次问答的检索和生成也都会消耗Token。售前必须帮助客户预估成本，避免后续产生费用争议。

· **B（正确）**：这是法律场景下的核心挑战。普通的分段可能切碎一个完整的法条或合同项，导致检索失败或误解。必须根据法律文档的结构特点进行精细化的分段参数调整。

· **C（错误）**：模型选择并非越贵越好。许多强大的模型（如GPT-3.5-Turbo、Claude Haiku等）在理解结构化文本方面表现已足够出色，且成本更低。应建议客户根据效果和成本的平衡（POC测试）来选择，而非盲目追求最顶级模型。

· **D（正确）**：海量文档的索引是耗时操作，必须管理客户预期。同时，法律文档会更新，如何高效地同步和更新索引是保证系统可用性的关键，必须提前设计流程。

· **E（正确）**：对于法律、医疗等高风险领域，提示词中的免责声明和范围限定至关重要，这是产品安全和合规性的基本要求。同时，优雅地处理“未知问题”能极大提升用户体验和专业度。

· **F（错误）**：Dify的知识库检索通常依赖于云端的向量数据库服务，其性能和速度由服务提供商保障，**并不**直接依赖于客户本地的GPU算力。本地部署除外，但标准SaaS模式无需此考虑。这是一个迷惑项，用于考察对架构原理的理解。

**3. 【多选题】知识库在完成文档处理并索引后，其工作原理包含以下哪些关键步骤？**\
A. 将用户的自然语言问题转换为向量（Vectorize）。\
B. 在向量数据库中进行相似度搜索，找到最相关的文本片段。\
C. 将检索到的文本片段作为上下文，与用户问题一同组合成完整的提示词（Prompt）发送给LLM。\
D. 直接修改大语言模型内部的权重参数，使其记住知识库内容。\
E. 将检索到的文本片段先翻译成英文，再发送给LLM。\
**答案：A, B, C**\
**解析：** 这是RAG（检索增强生成）的标准流程：A是“问”，B是“搜”，C是“答”。D是完全错误的，知识库不会改变LLM本身。E不是必需步骤，多模型可以直接处理中文向量和中文问题。

 
