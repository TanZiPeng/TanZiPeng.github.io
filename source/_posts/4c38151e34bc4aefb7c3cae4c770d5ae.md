---
layout: post
title: Unified-API 接口文档
abbrlink: 4c38151e34bc4aefb7c3cae4c770d5ae
tags: []
categories:
  - 工作笔记
  - 测试相关
date: 1756965965837
updated: 1756970206828
---

<!-- 自定义样式开始 -->

<style>
/* 隐藏顶部导航栏 (包括Joplin图标和链接) */
body.page-note nav.navbar {
    display: none !important;
}

/* 隐藏底部的“Powered by Joplin”的页脚 (可选) */
body.page-note > div.footer {
    display: none !important;
}

/* 调整页面内容，使其从顶部开始（可选，避免隐藏顶部导航后页面内容没有抬高） */
body.page-note > div.content {
    padding-top: 20px !important; 
}
</style>

  <!-- 自定义样式结束-->

# `/api/v1/chat/completions` 完整接口文档

## 接口概述

该接口提供与大语言模型的聊天补全功能，**完全兼容 OpenAI Chat Completions 接口规范**，支持通过 HTTP POST 请求与指定模型交互，同时支持流式/非流式响应，满足不同场景下的调用需求。

## 接口信息

- **接口地址**：`https://unifiedapi.cloud/api/v1/chat/completions`
- **请求方法**：`POST`
- **内容类型**：`application/json`
- **响应格式**：`application/json`（非流式）、`text/event-stream`（流式）

## 请求参数

### 1. 请求头（Headers）

| 参数名             | 类型     | 必选 | 描述                                                                | 完整示例                                                               |
| --------------- | ------ | -- | ----------------------------------------------------------------- | ------------------------------------------------------------------ |
| `accept`        | string | 是  | 指定接受的响应格式，非流式响应固定为 `application/json`，流式响应需改为 `text/event-stream` | 非流式：`accept: application/json`  <br>流式：`accept: text/event-stream` |
| `Authorization` | string | 是  | 认证令牌，格式固定为 `Bearer <token>`，其中 `<token>` 替换为实际的访问令牌               | `Authorization: Bearer your_unified_key`                           |
| `Content-Type`  | string | 是  | 声明请求体的内容类型，固定为 `application/json`（无论流式/非流式）                       | `Content-Type: application/json`                                   |
| `User-Agent`    | string | 否  | 可选，标识请求来源的客户端信息（如编程语言、SDK 版本），便于问题排查                              | `User-Agent: Python/3.10 openai-python/1.13.3`                     |

### 2. 请求体（Body）

| 参数名                  | 类型           | 必选 | 描述                                          | 示例                                 |
| -------------------- | ------------ | -- | ------------------------------------------- | ---------------------------------- |
| `model`              | string       | 是  | 要使用的模型名称，支持跨厂商模型                            | `google/gemini-2.5-pro`            |
| `messages`           | array        | 是  | 聊天消息数组，包含对话历史，格式与 OpenAI 完全一致               | 见下方请求示例                            |
| `messages[].role`    | string       | 是  | 消息角色                                        | `user`（用户），`system`(系统)            |
| `messages[].content` | string       | 是  | 消息内容，`system` 角色内容可定义助手行为                   | `"system": "始终用简洁的口语化中文回答"`        |
| `stream`             | boolean      | 否  | 是否启用流式响应，默认 `false`（非流式）                    | `true`（流式）、`false`（非流式）            |
| `temperature`        | number       | 否  | 随机性参数，范围 0-2，值越高回答越随机，默认 `0.7`              | `0.3`（精准）、`1.5`（有创意）               |
| `top_p`              | number       | 否  | 核采样参数，范围 0-1，与 `temperature` 二选一使用，默认 `1.0` | `0.9`（优先高概率词汇）                     |
| `max_tokens`         | integer      | 否  | 生成回答的最大令牌数，默认根据模型上限自动调整                     | `512`（限制短回答）、`2048`（长回答）           |
| `stop`               | string/array | 否  | 停止符，当模型生成到该字符时停止，默认无                        | `"END"`（单个停止符）、`["。", "！"]`（多个停止符） |
| `presence_penalty`   | number       | 否  | 话题新颖性惩罚，范围 -2-2，正值减少重复内容，默认 `0`             | `1.2`（鼓励新话题）                       |
| `frequency_penalty`  | number       | 否  | 词汇重复惩罚，范围 -2-2，正值减少高频词使用，默认 `0`             | `0.8`（避免重复用词）                      |
| `user`               | string       | 否  | 用户唯一标识，用于区分不同用户，避免对话混淆                      | `"user_123456"`                    |

## 请求示例

### 1. 非流式响应请求示例（curl）

```bash
curl -X 'POST' \
  'https://unifiedapi.cloud/api/v1/chat/completions' \
  -H 'accept: application/json' \   #流式输出替换为 text/event-stream 即可
  -H 'Authorization: Bearer your_unified_key' \
  -H 'Content-Type: application/json' \
  -H 'User-Agent: curl/7.88.1' \
  -d '{
    "model": "google/gemini-2.5-pro",
    "messages": [
      {
        "role": "system",
        "content": "用3句话以内的口语化中文回答，语气亲切"
      },
      {
        "role": "user",
        "content": "你好，请用中文介绍一下你自己。"
      }
    ],
    "temperature": 0.5,
    "max_tokens": 10000，
    "stream": false    \   #流式输出设置为 true 即可
  }'
```

### 2. 非流式响应请求示例（Python）

```python
import requests
import json

url = "https://unifiedapi.cloud/api/v1/chat/completions"
headers = {
    "accept": "application/json",
    "Authorization": "Bearer your_unified_key",
    "Content-Type": "application/json",
    "User-Agent": "Python/3.10 requests/2.31.0"
}
payload = {
    "model": "anthropic/claude-3-opus-20240229",
    "messages": [
        {"role": "user", "content": "推荐一本适合新手的编程书籍"},
        {"role": "assistant", "content": "推荐《Python编程：从入门到实践》，适合零基础新手，包含理论和实战案例。"},
        {"role": "user", "content": "这本书需要有编程基础吗？"}
    ],
    "stream": False,
    "top_p": 0.9,
    "stop": ["。"]
}

response = requests.post(url, headers=headers, data=json.dumps(payload))
print(response.json())
```

### 3. 流式响应请求示例（JavaScript）

```javascript
const axios = require('axios');

const url = 'https://unifiedapi.cloud/api/v1/chat/completions';
const headers = {
  'accept': 'text/event-stream',
  'Authorization': 'Bearer your_unified_key',
  'Content-Type': 'application/json',
  'User-Agent': 'Node.js/18.x axios/1.6.8'
};

const data = {
  "model": "google/gemini-2.5-pro",
  "messages": [
    {
      "role": "system",
      "content": "用3句话以内的口语化中文回答，语气亲切"
    },
    {
      "role": "user",
      "content": "你好，请用中文介绍一下你自己。"
    }
  ],
  "stream": true,
  "temperature": 0.5
};

axios.post(url, data, { 
  headers: headers,
  responseType: 'stream'
})
.then(response => {
  response.data.on('data', chunk => {
    const lines = chunk.toString().split('\n');
    for (const line of lines) {
      if (line.trim() === 'data: [DONE]') {
        console.log('Stream completed');
        return;
      }
      if (line.startsWith('data: ')) {
        const data = JSON.parse(line.slice(6));
        if (data.choices && data.choices[0].delta.content) {
          process.stdout.write(data.choices[0].delta.content);
        }
      }
    }
  });
})
.catch(error => {
  console.error('Error:', error);
});
```

## 响应参数

### 1. 非流式响应

```json
{
    "id": "chatcmpl-5a30a2a2-9f8e-4e8d-a855-54d0afee6d9d",
    "object": "chat.completion",
    "created": 1756965162,
    "model": "google/gemini-2.5-pro",
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "你好！很高兴能向你介绍我自己。\n\n我是一个大型语言模型（Large Language Model），由 Google 训练和开发。\n\n你可以把我理解为一个非常庞大、知识渊博的“数字大脑”或“对话伙伴”。我的核心是基于海量的文本和代码数据进行学习，从而学会了理解和生成人类语言。\n\n**我的主要能力包括：**\n\n1.  **回答问题**：我可以回答你提出的各种问题，无论是关于科学、历史、文化，还是日常生活的小知识。\n2.  **生成文本**：我可以帮你写文章、诗歌、邮件、故事、歌词，甚至代码。\n3.  **总结与分析**：如果你给我一段长文或复杂的信息，我可以帮你提炼要点、进行总结。\n4.  **翻译**：我具备在多种语言之间进行翻译的能力。\n5.  **创意与头脑风暴**：当你需要灵感时，我们可以一起进行头脑风暴，探索新的想法和可能性。\n6.  **对话聊天**：当然，我们也可以像朋友一样轻松地聊天！\n\n**不过，我也有一些重要的局限性：**\n\n*   **没有个人情感和意识**：我没有真实的感受、信念或个人经历。我的回答是基于我所学到的数据模式生成的。\n*   **知识有截止日期**：我的知识主要基于我训练数据截止的时间点，所以对于最新的事件可能不够了解。\n*   **可能会犯错**：虽然我力求准确，但有时也可能会提供不准确或不完整的信息。对于非常重要的信息，建议你进行多方核实。\n\n总而言之，我是一个功能强大的工具和伙伴，我的目标是利用我的知识和能力，为你提供帮助、激发你的创造力，并成为一个有用、可靠的交流伙伴。\n\n请随时向我提问或提出你的需求，我非常乐意与你交流！"
            },
            "finish_reason": "stop"
        }
    ],
    "usage": {
        "prompt_tokens": 9,
        "completion_tokens": 406,
        "total_tokens": 1965
    }
}
```

### 2. 流式响应（text/event-stream 格式）

```
data: {"id":"chatcmpl-5a30a2a2-9f8e-4e8d-a855-54d0afee6d9d","object":"chat.completion.chunk","created":1756965162,"model":"google/gemini-2.5-pro","system_fingerprint":"fp_123abc","choices":[{"index":0,"delta":{"content":"你好呀"},"finish_reason":null}]}

data: {"id":"chatcmpl-5a30a2a2-9f8e-4e8d-a855-54d0afee6d9d","object":"chat.completion.chunk","created":1756965162,"model":"google/gemini-2.5-pro","system_fingerprint":"fp_123abc","choices":[{"index":0,"delta":{"content":"！我是能和你聊天的AI"},"finish_reason":null}]}

data: {"id":"chatcmpl-5a30a2a2-9f8e-4e8d-a855-54d0afee6d9d","object":"chat.completion.chunk","created":1756965162,"model":"google/gemini-2.5-pro","system_fingerprint":"fp_123abc","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}

data: [DONE]
```

## 错误处理

| 错误代码                      | 描述      | 解决方法                                                    |
| ------------------------- | ------- | ------------------------------------------------------- |
| 401 Unauthorized          | 认证失败    | 检查令牌是否过期、格式是否为 `Bearer <token>`                         |
| 400 Bad Request           | 请求参数错误  | 常见原因：`model` 名称错误、`messages` 数组格式非法、`max_tokens` 超过模型上限 |
| 403 Forbidden             | 权限不足    | 确认令牌是否有调用目标模型的权限，或账号是否被限制                               |
| 404 Not Found             | 接口地址错误  | 确认接口地址为 `/api/v1/chat/completions`，无误写                  |
| 429 Too Many Requests     | 请求频率超限  | 降低调用频率，或联系服务商提升配额                                       |
| 500 Internal Server Error | 服务器内部错误 | 重试请求，若持续失败联系服务提供商                                       |
| 503 Service Unavailable   | 服务暂不可用  | 模型正在维护或负载过高，稍后重试                                        |

## 注意事项

1. **OpenAI 兼容性**：该接口可直接复用 OpenAI SDK 调用，只需替换 `your_unified_key` ，无需修改代码逻辑。
2. **流式响应适配**：启用 `stream: true` 时，需将请求头 `accept` 设为 `text/event-stream`，并处理分块响应数据。
3. **模型参数差异**：部分模型可能不支持所有参数（如 `presence_penalty`），若返回参数无效错误，需参考具体模型文档调整请求字段。
4. **令牌计算规则**：不同厂商模型的令牌计算方式可能不同，`usage` 字段会返回厂商标准的令牌统计结果。
5. **安全提示**：请妥善保管您的访问令牌，避免在客户端代码中直接暴露令牌信息。

以上是完整的接口文档，包括所有请求参数、请求头、多种语言的请求示例、响应格式、错误处理和注意事项。同时提供了一个Python测试脚本，可用于快速验证API的功能，支持流式和非流式两种调用方式。

使用测试脚本时，只需将`your_unified_key`替换为您的实际密钥，即可测试不同模型和参数配置下的接口响应。脚本会自动处理流式响应的分块输出和非流式响应的完整解析。
